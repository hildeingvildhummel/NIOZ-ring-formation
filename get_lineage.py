import argparse
import numpy as np
import pandas as pd
import json
from collections import Counter
import operator

ap = argparse.ArgumentParser(description='Create a text file containing the predicted lineage using the NCBI taxonomy database. The output of this function are json files containing the annotations per contig/per gene. If the count table per sample is given a csv containing the counts per annotation per sample will be saved as well. If htseq files are given, a coverage dataframe per gene will be saved as a csv file.')
ap.add_argument('-db', '--database', required = True, help = 'The rankedlineage.dmp database of NCBI')
ap.add_argument('-b6', '--blastp6output', required = True, help = 'Give the blast table created DIAMOND with output type 6, with a column containing the taxID as the final column (staxids)')
ap.add_argument('-t', '--table', required = True, help = 'Give the PROKKA tbl file')
ap.add_argument('-c', '--counttable', required = False, help = 'Give the file containing the counts per sample annotated by Bowtie. This is not a required argument. If given, a csv file containing the counts per annotation is created and saved.')
ap.add_argument('-o', '--output_name', required = True, help = 'Give the basename of the file to be saved')
ap.add_argument('-i', '--index', required = False, help = 'The index of the column containing the taxID, starting the count with zero. So, the first column is 0, the second column is 1, etc. (Default is the final column)')
ap.add_argument('-gc', '--gene_counts', nargs='+', required = False, help = 'Give the files containing the counts per gene generated by htseq, the files should be given space delimited.')

args, leftovers = ap.parse_known_args()

#Initiate an empty dictionary
d = {}
#Open de database
with open(args.database) as f:
    #Iterate over the lines of the database
    for line in f:
        #Convert to the correct format
       line = line.replace('\t|\n', '').split('\t|\t')[::-1]
       #Convert database to a useable dictionary
       d[line[-1]] = line[:-1]
#Open and read the DIAMOND output
file_2 = open(args.blastp6output)
file_2 = file_2.readlines()
#Create 2 empty dictionaries
sub_dict = {}
sub_dict_2 = {}
#Iterate over the DIAMOND output
for k in file_2:
    #Split the line
    k = k.split('\t')
    #Extract the gene name
    n = k[0].replace('\n', '')

    try:
        #If an index is specified...
        if args.index is not None:
            #Check if the index specified is the last column
            if int(args.index) != len(k)-1:
                #Convert the taxID to correct format
                f = k[int(args.index)].split(';')[0]
            #If the index specified is not the last index
            else:
                #Convert the taxID to correct format
                f = k[int(args.index)].replace('\n', "").split(';')[0]

        #If no index is specified
        else:
            #Set the final index as the place of the taxID and convert it to the correct format
            f = k[len(k) - 1].replace('\n', "").split(';')[0]

        #Extract the lineage from the dictionary database
        lineage = d[f]

    #If not able to extract the taxID from either the DIAMOND output or the database set 'root' as the lineage
    except:
        lineage = ['root']
    #Add the lineage to a dictionary with the gene name as key
    sub_dict[n] = lineage
    #Check whether the final level of the lineage is not empty
    if lineage[-1] is not None:
        #If so, save the final level of the lineage to a new dictionary
        sub_dict_2[n] = lineage[-1]
    #Else..
    else:
        #Save on level up of the lineage to a new dictionary
        sub_dict_2[n] = lineage[-2]
#Open a txt file and save gene name and their lineage to a json file
with open(args.output_name + '_tags.txt', 'w') as file:
     file.write(json.dumps(sub_dict))
#Open and read the table of Prokka
file3 = open(args.table,  'r')
file3 = file3.read().split('>Feature ')
#Convert to the right format
new_file = [s.split('\t') for s in file3 if '\t' and 'locus_tag' in s]
#Create 2 empty dictionaries
dict = {}
using_dict = {}
#Create 2 empty lists
contigs = []
locus_tags = []
#Iterate over the Prokka table output
for s in new_file:
    #Extract hthe name of the contig
    contig = s[0].split('\n')[0]
    #Find the places of gene annotation
    indexList = np.where(np.array(s) == 'locus_tag')[0]
    #Add 1 to all indices found
    indexList += 1
    #Check wheter more than 1 gene was found on the contig
    if len(indexList) > 1:
        #Create an empty list
        lineage_list = []
        #Iterate over all the detected genes
        for i in indexList:
            #Convert to the correct format
            tag = s[i].replace('\n','')
            #Check if the gene is within previous created dictionary
            if tag in sub_dict.keys():
                #Append the corresponding lineage to list
                lineage_list.append(sub_dict[tag])
        #Check if the length of the created list is longer than 0..
        if len(lineage_list) > 0 :
            #Save the list to the dictionary with contig as key
            dict[contig] = lineage_list
            #Iterate over the length of the list
            for k in range(len(max(lineage_list, key = len))):
                try:
                    #Extract the lowest value of the lineage
                    pred = list(zip(*lineage_list))[k]
                except:
                    continue
                #Count the predictions of the contig
                d_pred = Counter(pred)
                #Normalize it by dividing it by the number of genes on the contig and check whether these are above 0.5
                d_pred = {k: v / len(pred) for k, v in d_pred.items() if float(v/len(pred)) > 0.5}
                #Convert prediction to the right format
                try:
                    best = max(d_pred.items(), key=operator.itemgetter(1))[0]
                    best = ' '.join(best.split(" ")[:2])
                    if not best:
                        best = max(d_pred.items(), key=operator.itemgetter(1))[1]
                        best = ' '.join(best.split(" ")[:2])
                    #Save annotation of the contig to the dictionary
                    using_dict[contig] = best
                except:
                    continue
    #If only one gene is present on the contig..
    else:
        #Convert annotation to the correct format
        tag = s[int(indexList)].replace('\n','')
        #Check if it is annotated..
        if tag in sub_dict.keys():
            #If so, save the annotation to the dictionary
            using_dict[contig] = ' '.join(lineage[-1].split(' ')[:2])
            #Save the lineage to the other dictionary
            dict[contig] = lineage
        else:
            continue
#Save the dictionary with the lineages to a txt file
with open(args.output_name + '_list.txt', 'w') as file:
     file.write(json.dumps(dict))
#Save the highest annotations to a txt file
with open(args.output_name + '.txt', 'w') as file:
     file.write(json.dumps(using_dict))
#Check if a coverage file is given..
if args.counttable is not None:
    #If so, open it.
    df = pd.read_csv(args.counttable, index_col = 0)
    #Extract the index as Series
    s = df.index.to_series()
    #Map the index using the highest annotation dictionary
    df.index = s.map(using_dict).fillna(s)
    #Save the index to a column
    df['column'] = df.index
    df = df[~df["column"].str.contains("k141", na=False)]
    #Sum the contigs that are annotated teh same
    df = df.groupby(['column']).sum()
    #Print the top rows
    print(df.head(5))
    #Save the generated dataframe as csv file
    df.to_csv(args.output_name + '_genus.csv')

#If gene coverage files are given..
if args.gene_counts is not None:
    #Initiate a DataFrame
    super_df = pd.DataFrame()
    #Initiate a counter
    counter = 0
    #Iterate over the coverage files
    for gf in args.gene_counts:
        #Create 9 lists
        counts = []
        genes = []
        kingdoms = []
        phyla = []
        classes = []
        orders = []
        families = []
        genuses = []
        species = []
        #Open the selected file
        with open(gf) as f:
            #Read and split the file
            f = f.read().split('\n')
            #Check if the counter is equal to 0...
            if counter == 0:
                #Iterate over the lines of the file..
                for line in f[:-5]:
                    #Check if the gene is annotated..
                    try:
                        lineage_list = sub_dict[line.split('\t')[0]]
                    except:
                        continue
                    #If so, save the coverage and the gene name to the lists
                    counts.append(line.split('\t')[1])
                    genes.append(line.split('\t')[0])
                    #Save the kingdom to the list if known, otherwise save 'root'
                    try:
                        kingdoms.append(lineage_list[0])
                    except:
                        kingdoms.append('root')
                    #Save the phylum to the list if known, otherwise save 'unknown'
                    try:
                        phyla.append(lineage_list[2])
                    except:
                        phyla.append('unknown')
                    #Save the class to the list if known, otherwise save 'unknown'
                    try:
                        classes.append(lineage_list[3])
                    except:
                        classes.append('unknown')
                    #Save the order to the list if known, otherwise save 'unknown'
                    try:
                        orders.append(lineage_list[4])
                    except:
                        orders.append('unknown')
                    #Save the family to the list if known, otherwise save 'unknown'
                    try:
                        families.append(lineage_list[5])
                    except:
                        families.append('unknown')
                    #Save the genus to the list if known, otherwise save 'unknown'
                    try:
                        genuses.append(lineage_list[6])
                    except:
                        genuses.append('unknown')
                    #Save the species to the list if known, otherwise save 'unknown'
                    try:
                        species.append(lineage_list[7])
                    except:
                        species.append('unknown')
                #Save the list to the corresponding column within the Initiated DataFrame
                super_df['Kingdom'] = kingdoms
                super_df['Phylum'] = phyla
                super_df['Class'] = phyla
                super_df['Order'] = orders
                super_df['Family'] = families
                super_df['Genus'] = genuses
                super_df['Species'] = species
                super_df['Genes'] = genes
                #Set the gene names as index
                super_df.set_index('Genes', inplace=True)
                #Create a column with the coverages of the samples
                super_df[gf] = counts
                #Print the length of the created dataframe
                print(len(super_df))
            #If the counter is unequal to 0..
            else:
                #Iterate over the lines of the coverage file...
                for line in f[:-5]:
                    #If the gene is annotated..
                    if line.split('\t')[0] in sub_dict.keys():
                        #Save the coverage to the list
                        counts.append(line.split('\t')[1])
                #Save the coverage of the selected sample to the dataframe
                super_df[gf] = counts
                #Print the top rows of the dataframe
                print(super_df.head(5))
            #Add 1 to the counter
            counter += 1
    #Save the generated DataFrame as a csv file
    super_df.to_csv(args.output_name + '_genes.csv')
